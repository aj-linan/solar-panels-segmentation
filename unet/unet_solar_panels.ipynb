{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook was executed on Kaggle. Paths and outputs remain as in the original Kaggle notebook due to computational limitations. You can view the original notebook here: https://www.kaggle.com/code/mrhendley/solar-panels-segmentation-u-net-efficientnet-512\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# I. Import libraries and GPU configuration\n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-16T17:00:00.100000Z",
     "iopub.status.busy": "2025-12-16T17:00:00.099649Z",
     "iopub.status.idle": "2025-12-16T17:00:07.889256Z",
     "shell.execute_reply": "2025-12-16T17:00:07.888449Z",
     "shell.execute_reply.started": "2025-12-16T17:00:00.099970Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!pip install segmentation-models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-16T17:00:08.981690Z",
     "iopub.status.busy": "2025-12-16T17:00:08.981387Z",
     "iopub.status.idle": "2025-12-16T17:00:19.223366Z",
     "shell.execute_reply": "2025-12-16T17:00:19.222490Z",
     "shell.execute_reply.started": "2025-12-16T17:00:08.981660Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import shutil\n",
    "import tensorflow as tf\n",
    "from zipfile import ZipFile \n",
    "import keras.backend as K\n",
    "from tensorflow.keras.callbacks import Callback, EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "os.environ['SM_FRAMEWORK'] = 'tf.keras'\n",
    "import segmentation_models as sm\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-12-16T16:59:16.223844Z",
     "iopub.status.idle": "2025-12-16T16:59:16.224210Z",
     "shell.execute_reply": "2025-12-16T16:59:16.224062Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "print(\"--- HARDWARE VERIFICATION ---\")\n",
    "\n",
    "# 1. CHECK FOR AVAILABLE GPUS\n",
    "# Lists the physical devices available for TensorFlow.\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "\n",
    "if gpus:\n",
    "    try:\n",
    "        # Configure TensorFlow to use the detected GPU (assuming one is present).\n",
    "        gpu_device = gpus[0]\n",
    "        tf.config.set_visible_devices(gpu_device, 'GPU')\n",
    "\n",
    "        # 2. CONFIGURE MEMORY GROWTH\n",
    "        # Enables gradual memory growth . \n",
    "        # This is vital for large images (512x512) as it reserves GPU memory only as needed,\n",
    "        # preventing \"Out of Memory\" (OOM) errors.\n",
    "        tf.config.experimental.set_memory_growth(gpu_device, True)\n",
    "        \n",
    "        print(f\"Success: GPU detected and configured: {gpu_device.name}\")\n",
    "        print(\"Training will use the graphics accelerator.\")\n",
    "        \n",
    "    except RuntimeError as e:\n",
    "        # Error handling if configuration fails (e.g., if executed too late).\n",
    "        print(f\"Error configuring GPU: {e}\")\n",
    "        print(\"Ensure this cell runs before building any model.\")\n",
    "else:\n",
    "    print(\"Warning: No GPU detected. Training will run on the CPU and will be slow.\")\n",
    "\n",
    "# 3. VERIFY STATE\n",
    "# Displays the devices TensorFlow is actively utilizing.\n",
    "print(\"\\n--- CONFIGURATION STATUS ---\")\n",
    "print(f\"Visible devices for TF: {tf.config.get_visible_devices()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# II. Utility Functions\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-16T17:00:22.508634Z",
     "iopub.status.busy": "2025-12-16T17:00:22.508315Z",
     "iopub.status.idle": "2025-12-16T17:00:22.513567Z",
     "shell.execute_reply": "2025-12-16T17:00:22.512778Z",
     "shell.execute_reply.started": "2025-12-16T17:00:22.508602Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def prepare_dataframe(image_path, name):\n",
    "    solar_ids = []\n",
    "    paths = []\n",
    "    for dirname, _, filenames in os.walk(image_path):\n",
    "        for filename in filenames:\n",
    "            path = os.path.join(dirname, filename)    \n",
    "            paths.append(path)\n",
    "\n",
    "            solar_id = filename.split(\".\")[0]\n",
    "            solar_ids.append(solar_id)\n",
    "\n",
    "    d = {\"id\": solar_ids, name: paths}\n",
    "    df = pd.DataFrame(data = d)\n",
    "    df = df.set_index('id')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-16T17:00:26.827920Z",
     "iopub.status.busy": "2025-12-16T17:00:26.827617Z",
     "iopub.status.idle": "2025-12-16T17:00:26.832578Z",
     "shell.execute_reply": "2025-12-16T17:00:26.831770Z",
     "shell.execute_reply.started": "2025-12-16T17:00:26.827896Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def display(display_list):\n",
    "    plt.figure(figsize=(15, 15))\n",
    "\n",
    "    title = ['Input Image', 'True Mask', 'Predicted Mask']\n",
    "\n",
    "    for i in range(len(display_list)):\n",
    "        plt.subplot(1, len(display_list), i+1)\n",
    "        plt.title(title[i])\n",
    "        plt.imshow(tf.keras.preprocessing.image.array_to_img(display_list[i]))\n",
    "        plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# III. Dataset Preparation\n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-16T17:00:31.102021Z",
     "iopub.status.busy": "2025-12-16T17:00:31.101669Z",
     "iopub.status.idle": "2025-12-16T17:00:33.040465Z",
     "shell.execute_reply": "2025-12-16T17:00:33.039654Z",
     "shell.execute_reply.started": "2025-12-16T17:00:31.101986Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!mkdir train\n",
    "!mkdir train_masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-16T17:00:40.195972Z",
     "iopub.status.busy": "2025-12-16T17:00:40.195661Z",
     "iopub.status.idle": "2025-12-16T17:08:29.664646Z",
     "shell.execute_reply": "2025-12-16T17:08:29.663933Z",
     "shell.execute_reply.started": "2025-12-16T17:00:40.195941Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#copy all images to image folder and save labels to label folder with same name as correspoding image\n",
    "\n",
    "root_dir = '/kaggle/input/solar-panel-detection-and-identification/PV03'\n",
    "resolution = 'PV03'\n",
    "data_dir = os.path.join(root_dir)#,resolution)\n",
    "\n",
    "image_root = '/kaggle/working/train'\n",
    "label_root = '/kaggle/working/train_masks'\n",
    "if not os.path.isdir(image_root):\n",
    "    os.mkdir(image_root)\n",
    "if not os.path.isdir(label_root):\n",
    "    os.mkdir(label_root)\n",
    "\n",
    "images = list()\n",
    "labels = list()\n",
    "\n",
    "for (dirpath, dirnames, filenames) in os.walk(data_dir):\n",
    "    # img_names += [os.path.join(dirpath, file) for file in filenames]\n",
    "    images += [os.path.join(dirpath, file) for file in filenames]\n",
    "\n",
    "labels += [i for i in filter(lambda score: '_label.bmp' in score, images)]\n",
    "images = [i for i in filter(lambda score: '_label.bmp' not in score, images)]\n",
    "\n",
    "for img_path in images:\n",
    "    img = Image.open(img_path).convert(\"RGB\")\n",
    "    img = img.resize((512, 512), resample=Image.BILINEAR)\n",
    "    dst = os.path.join(image_root, os.path.basename(img_path).replace('.bmp', '.png'))\n",
    "    img.save(dst, 'PNG')\n",
    "\n",
    "for label_path in labels:\n",
    "    img = Image.open(label_path)\n",
    "\n",
    "    # Forzar monocanal\n",
    "    img = img.convert(\"L\")\n",
    "\n",
    "    # Resize SIN interpolar\n",
    "    img = img.resize((512, 512), resample=Image.NEAREST)\n",
    "\n",
    "    # Binarizar explícitamente\n",
    "    img = np.array(img)\n",
    "    img = (img > 0).astype(np.uint8) * 255\n",
    "    img = Image.fromarray(img)\n",
    "\n",
    "    file_name = os.path.basename(label_path).replace('_label.bmp', '.png')\n",
    "    dst = os.path.join(label_root, file_name)\n",
    "    img.save(dst, 'PNG')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-16T17:13:26.074018Z",
     "iopub.status.busy": "2025-12-16T17:13:26.073681Z",
     "iopub.status.idle": "2025-12-16T17:13:26.081254Z",
     "shell.execute_reply": "2025-12-16T17:13:26.080435Z",
     "shell.execute_reply.started": "2025-12-16T17:13:26.073987Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "print(\"Train set:  \", len(os.listdir(\"/kaggle/working/train\")))\n",
    "print(\"Train masks:\", len(os.listdir(\"/kaggle/working/train_masks\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-16T17:13:28.360396Z",
     "iopub.status.busy": "2025-12-16T17:13:28.360103Z",
     "iopub.status.idle": "2025-12-16T17:13:28.405553Z",
     "shell.execute_reply": "2025-12-16T17:13:28.404893Z",
     "shell.execute_reply.started": "2025-12-16T17:13:28.360372Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "df = prepare_dataframe('/kaggle/working/train', \"solar_path\")\n",
    "mask_df = prepare_dataframe('/kaggle/working/train_masks', \"mask_path\")\n",
    "df[\"mask_path\"] = mask_df[\"mask_path\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IV. Data Pre-processing and Augmentation\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will perform a simple augmentation of flipping an image and then normalize the image pixel in between 0 and 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-16T17:13:33.128577Z",
     "iopub.status.busy": "2025-12-16T17:13:33.128271Z",
     "iopub.status.idle": "2025-12-16T17:13:33.137837Z",
     "shell.execute_reply": "2025-12-16T17:13:33.136898Z",
     "shell.execute_reply.started": "2025-12-16T17:13:33.128549Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Definition of the output image size. All images will be resized to 512x512.\n",
    "img_size = [512, 512] \n",
    "\n",
    "def data_augmentation(solar_img, mask_img):\n",
    "\n",
    "    if tf.random.uniform(()) > 0.5:\n",
    "        solar_img = tf.image.flip_left_right(solar_img)\n",
    "        mask_img = tf.image.flip_left_right(mask_img)\n",
    "\n",
    "    if tf.random.uniform(()) > 0.5:\n",
    "        solar_img = tf.image.flip_up_down(solar_img)\n",
    "        mask_img = tf.image.flip_up_down(mask_img)\n",
    "\n",
    "    k = tf.random.uniform((), minval=0, maxval=4, dtype=tf.int32)\n",
    "    solar_img = tf.image.rot90(solar_img, k)\n",
    "    mask_img = tf.image.rot90(mask_img, k)\n",
    "\n",
    "    solar_img = tf.image.random_brightness(solar_img, 0.1)\n",
    "    solar_img = tf.image.random_contrast(solar_img, 0.9, 1.1)\n",
    "\n",
    "    return solar_img, mask_img\n",
    "\n",
    "def preprocessing(solar_path, mask_path):\n",
    "\n",
    "    # --- IMAGE ---\n",
    "    solar_img = tf.io.read_file(solar_path)\n",
    "    solar_img = tf.image.decode_png(solar_img, channels=3)\n",
    "    solar_img = tf.image.resize(solar_img, img_size)\n",
    "    solar_img = tf.cast(solar_img, tf.float32) / 255.0\n",
    "\n",
    "    # --- MASK ---\n",
    "    mask_img = tf.io.read_file(mask_path)\n",
    "    mask_img = tf.image.decode_png(mask_img, channels=1)\n",
    "\n",
    "    mask_img = tf.image.resize(\n",
    "        mask_img,\n",
    "        img_size,\n",
    "        method=tf.image.ResizeMethod.NEAREST_NEIGHBOR\n",
    "    )\n",
    "\n",
    "    mask_img = tf.cast(mask_img > 0, tf.float32)\n",
    "\n",
    "    return solar_img, mask_img\n",
    "\n",
    "\n",
    "# Assuming df_train has ~4616 rows (this number is used for the shuffle buffer)\n",
    "DATASET_SIZE = 2308\n",
    "\n",
    "def create_dataset(df, train=False):\n",
    "\n",
    "    ds = tf.data.Dataset.from_tensor_slices(\n",
    "        (df[\"solar_path\"].values, df[\"mask_path\"].values)\n",
    "    )\n",
    "\n",
    "    ds = ds.map(preprocessing, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "\n",
    "    if train:\n",
    "        ds = ds.map(data_augmentation, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "        ds = ds.shuffle(DATASET_SIZE)\n",
    "    else:\n",
    "        ds = ds.cache()\n",
    "\n",
    "    ds = ds.prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "    return ds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-16T17:17:28.925559Z",
     "iopub.status.busy": "2025-12-16T17:17:28.925121Z",
     "iopub.status.idle": "2025-12-16T17:17:29.163242Z",
     "shell.execute_reply": "2025-12-16T17:17:29.161841Z",
     "shell.execute_reply.started": "2025-12-16T17:17:28.925526Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Now we will split the dataset into train and test\n",
    "train_df, valid_df = train_test_split(df, random_state=27, test_size=.2)\n",
    "train = create_dataset(train_df, train = True)\n",
    "valid = create_dataset(valid_df, train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-16T17:17:31.212973Z",
     "iopub.status.busy": "2025-12-16T17:17:31.212613Z",
     "iopub.status.idle": "2025-12-16T17:17:48.658678Z",
     "shell.execute_reply": "2025-12-16T17:17:48.657888Z",
     "shell.execute_reply.started": "2025-12-16T17:17:31.212937Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "solar, mask = next(iter(train))\n",
    "print(\"Imagen:\", solar.shape, solar.dtype, tf.reduce_min(solar).numpy(), tf.reduce_max(solar).numpy())\n",
    "print(\"Máscara:\", mask.shape, tf.unique(tf.reshape(mask, [-1]))[0].numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-16T17:18:00.115576Z",
     "iopub.status.busy": "2025-12-16T17:18:00.115299Z",
     "iopub.status.idle": "2025-12-16T17:18:00.119028Z",
     "shell.execute_reply": "2025-12-16T17:18:00.118216Z",
     "shell.execute_reply.started": "2025-12-16T17:18:00.115552Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "TRAIN_LENGTH = len(train_df)\n",
    "BATCH_SIZE = 4\n",
    "BUFFER_SIZE = TRAIN_LENGTH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-16T17:18:22.452944Z",
     "iopub.status.busy": "2025-12-16T17:18:22.452620Z",
     "iopub.status.idle": "2025-12-16T17:18:22.459834Z",
     "shell.execute_reply": "2025-12-16T17:18:22.459168Z",
     "shell.execute_reply.started": "2025-12-16T17:18:22.452897Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_dataset = train.batch(BATCH_SIZE).repeat()\n",
    "valid_dataset = valid.batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-16T17:21:38.277430Z",
     "iopub.status.busy": "2025-12-16T17:21:38.277119Z",
     "iopub.status.idle": "2025-12-16T17:22:47.778697Z",
     "shell.execute_reply": "2025-12-16T17:22:47.777894Z",
     "shell.execute_reply.started": "2025-12-16T17:21:38.277400Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Let's look the image and it's corresponding mask\n",
    "for i in range(5):\n",
    "    for image, mask in train.take(i):\n",
    "        sample_image, sample_mask = image, mask\n",
    "        display([sample_image, sample_mask])\n",
    "        print(\"Images:\", image.shape, image.dtype)\n",
    "        print(\"Masks:\", mask.shape, mask.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# V. Model\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to use U-Net model. A U-Net consists of an encoder (downsampler) and decoder (upsampler). In-order to learn robust features, and reduce the number of trainable parameters, a pretrained model can be used as the encoder.The encoder will be a pretrained efficientnetb1 model which is prepared and ready to use in tf.keras.applications. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-16T17:39:06.359200Z",
     "iopub.status.busy": "2025-12-16T17:39:06.358847Z",
     "iopub.status.idle": "2025-12-16T17:39:08.985359Z",
     "shell.execute_reply": "2025-12-16T17:39:08.984545Z",
     "shell.execute_reply.started": "2025-12-16T17:39:06.359170Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# --- GLOBAL PARAMETER CONFIGURATION ---\n",
    "BACKBONE = 'efficientnetb1' \n",
    "INPUT_SHAPE = (512, 512, 3) \n",
    "CLASSES = 1 \n",
    "UNIFIED_LEARNING_RATE = 3e-4 # Low LR for stable fine-tuning\n",
    "LOCAL_ENCODER_WEIGHTS = '/kaggle/input/efficientnet-keras-weights/imagenet_1000/b2_notop.h5'\n",
    "\n",
    "# --- LOSS AND METRICS ---\n",
    "\n",
    "def dice_coef(y_true, y_pred, smooth=1e-6):\n",
    "    \"\"\"Calculates the Dice Coefficient for segmentation evaluation.\"\"\"\n",
    "    intersection = K.sum(y_true * y_pred, axis=[1,2,3])\n",
    "    union = K.sum(y_true, axis=[1,2,3]) + K.sum(y_pred, axis=[1,2,3])\n",
    "    return K.mean( (2. * intersection + smooth) / (union + smooth), axis=0)\n",
    "\n",
    "# Instantiate BinaryCrossentropy once for efficiency\n",
    "bce = tf.keras.losses.BinaryCrossentropy()\n",
    "\n",
    "def combined_loss(y_true, y_pred):\n",
    "    \"\"\"Combined loss (50% Dice Loss + 50% Binary Crossentropy) for stability.\"\"\"\n",
    "    dice_loss_val = 1 - dice_coef(y_true, y_pred)\n",
    "    return 0.5 * dice_loss_val + 0.5 * bce(y_true, y_pred)\n",
    "\n",
    "\n",
    "# --- 2. U-Net with efficientnetb1 Model Definition ---\n",
    "def build_unet_efficientnetb1(input_shape, classes, backbone):\n",
    "    \"\"\"\n",
    "    Construye el modelo U-Net con el backbone efficientnetb1.\n",
    "    \"\"\"\n",
    "    print(f\"Building U-Net model with backbone: {backbone}...\")\n",
    "    \n",
    "    model = sm.Unet( \n",
    "        backbone_name=backbone,\n",
    "        input_shape=input_shape,\n",
    "        encoder_weights= LOCAL_ENCODER_WEIGHTS, # Transfer Learning\n",
    "        classes=classes,\n",
    "        activation='sigmoid', # Sigmoid for binary output\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "\n",
    "# --- MODEL INSTANTIATION AND WEIGHT LOADING ---\n",
    "model_unet_efficientnetb1 = build_unet_efficientnetb1(\n",
    "    input_shape=INPUT_SHAPE,\n",
    "    classes=CLASSES,\n",
    "    backbone=BACKBONE\n",
    ")\n",
    "\n",
    "model = model_unet_efficientnetb1\n",
    "checkpoint_filepath = 'unet_efficientnetb1.h5'\n",
    "\n",
    "try:\n",
    "    model.load_weights(checkpoint_filepath)\n",
    "    print(f\"INFO: Weights loaded from {checkpoint_filepath}. Resuming training.\")\n",
    "except:\n",
    "    print(\"INFO: No saved weights found. Initializing from scratch.\")\n",
    "\n",
    "print(\"\\n--- U-Net (efficientnetb1) MODEL INSTANTIATED ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-16T17:39:14.959191Z",
     "iopub.status.busy": "2025-12-16T17:39:14.958818Z",
     "iopub.status.idle": "2025-12-16T17:39:15.133730Z",
     "shell.execute_reply": "2025-12-16T17:39:15.132944Z",
     "shell.execute_reply.started": "2025-12-16T17:39:14.959161Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# --- FINAL COMPILATION (All layers are already trainable) ---\n",
    "\n",
    "model.compile(\n",
    "    optimizer=Adam(learning_rate=UNIFIED_LEARNING_RATE),\n",
    "    loss=combined_loss, # Combined Loss (Dice + BCE)\n",
    "    metrics=[dice_coef, 'binary_accuracy', sm.metrics.iou_score]\n",
    ")\n",
    "print(f\"Model compiled with final LR: {UNIFIED_LEARNING_RATE}\")\n",
    "print(\"--- FINAL COMPILATION COMPLETE ---\")\n",
    "\n",
    "# --- MODEL ARCHITECTURE SUMMARY ---\n",
    "print(\"\\n--- MODEL ARCHITECTURE SUMMARY (U-Net with efficientnetb1) ---\")\n",
    "model.summary()\n",
    "\n",
    "for layer in model.layers:\n",
    "    if 'batch_normalization' in layer.name:\n",
    "        layer.trainable = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VI. Training the Model\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try out the model to see what it predicts before training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-15T16:04:22.862133Z",
     "iopub.status.busy": "2025-12-15T16:04:22.861827Z",
     "iopub.status.idle": "2025-12-15T16:04:28.635825Z",
     "shell.execute_reply": "2025-12-15T16:04:28.634914Z",
     "shell.execute_reply.started": "2025-12-15T16:04:22.862107Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "for images, masks in train_dataset.take(1):\n",
    "    for img, mask in zip(images, masks):\n",
    "        sample_image = img\n",
    "        sample_mask = mask\n",
    "        break\n",
    "def visualize(display_list):\n",
    "    plt.figure(figsize=(15, 15))\n",
    "    title = ['Input Image', 'True Mask', 'Predicted Mask']\n",
    "    for i in range(len(display_list)):\n",
    "        plt.subplot(1, len(display_list), i+1)\n",
    "        plt.title(title[i])\n",
    "        plt.imshow(tf.keras.preprocessing.image.array_to_img(display_list[i]))\n",
    "        plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "def show_predictions(sample_image, sample_mask):\n",
    "    pred_mask = model.predict(sample_image[tf.newaxis, ...])\n",
    "    pred_mask = pred_mask.reshape(img_size[0],img_size[1],1)\n",
    "    visualize([sample_image, sample_mask, pred_mask])\n",
    "    \n",
    "show_predictions(sample_image, sample_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# --- 1. DEFINITION OF PREDICTION CALLBACK ---\n",
    "class DisplayCallback(Callback):\n",
    "    \"\"\"Callback to display predictions during training.\"\"\"\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        # Only run every 5 epochs\n",
    "        if (epoch + 1) % 5 == 0:\n",
    "            try:\n",
    "                # Assuming show_predictions, sample_image, and sample_mask are defined\n",
    "                show_predictions(sample_image, sample_mask) \n",
    "            except NameError:\n",
    "                print(\"\\nWARNING: show_predictions/sample_data variables not found for DisplayCallback.\")\n",
    "\n",
    "\n",
    "# --- 2. UNIFIED CALLBACKS ---\n",
    "UNIFIED_EPOCHS = 40 # High number, EarlyStopping will stop training early\n",
    "\n",
    "callbacks_single_stage = [\n",
    "    DisplayCallback(),\n",
    "    # Reduce LR if val_loss plateaus\n",
    "    ReduceLROnPlateau(monitor=\"val_loss\", factor=0.5, patience=3, min_lr=1e-6, verbose=1),\n",
    "    # Early Stopping based on max val_dice_coef\n",
    "    EarlyStopping(monitor=\"val_dice_coef\", patience=5, mode=\"max\", restore_best_weights=True, verbose=1),\n",
    "    # Save best weights\n",
    "    ModelCheckpoint(checkpoint_filepath, save_weights_only=True, monitor=\"val_dice_coef\", mode=\"max\", save_best_only=True, verbose=1)\n",
    "]\n",
    "\n",
    "# --- 3. UNIFIED TRAINING ---\n",
    "\n",
    "print(f\"\\nStarting unified training for {UNIFIED_EPOCHS} epochs with initial LR={UNIFIED_LEARNING_RATE}.\")\n",
    "\n",
    "history_unified = model.fit(\n",
    "    train_dataset,\n",
    "    validation_data=valid_dataset,\n",
    "    epochs=UNIFIED_EPOCHS,\n",
    "    steps_per_epoch=TRAIN_LENGTH // BATCH_SIZE, \n",
    "    callbacks=callbacks_single_stage\n",
    ")\n",
    "\n",
    "print(\"\\nUnified training stage complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VI. Inferance\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "for i in range(5):\n",
    "    for image, mask in valid.take(i):\n",
    "        sample_image, sample_mask = image, mask\n",
    "        show_predictions(sample_image, sample_mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VI. Save and Load the Model \n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-28T10:43:44.471342Z",
     "iopub.status.busy": "2022-12-28T10:43:44.47082Z",
     "iopub.status.idle": "2022-12-28T10:43:44.653919Z",
     "shell.execute_reply": "2022-12-28T10:43:44.652989Z",
     "shell.execute_reply.started": "2022-12-28T10:43:44.4713Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "model.save(\"unet_efficientnetb1.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-11T12:57:39.868133Z",
     "iopub.status.busy": "2025-12-11T12:57:39.867885Z",
     "iopub.status.idle": "2025-12-11T12:57:39.877052Z",
     "shell.execute_reply": "2025-12-11T12:57:39.876234Z",
     "shell.execute_reply.started": "2025-12-11T12:57:39.868073Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def visualize_predicted(display_list):\n",
    "    plt.figure(figsize=(15, 15))\n",
    "    title = ['Input Image', 'Predicted Mask']\n",
    "    for i in range(len(display_list)):\n",
    "        plt.subplot(1, len(display_list), i+1)\n",
    "        plt.title(title[i])\n",
    "        plt.imshow(tf.keras.preprocessing.image.array_to_img(display_list[i]))\n",
    "        plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "def show_(sample_image):\n",
    "    pred_mask = model.predict(sample_image[tf.newaxis, ...])\n",
    "    pred_mask = pred_mask.reshape(img_size[0],img_size[1],1)\n",
    "    visualize_predicted([sample_image, pred_mask])\n",
    "    return pred_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-28T10:52:02.27316Z",
     "iopub.status.busy": "2022-12-28T10:52:02.27282Z",
     "iopub.status.idle": "2022-12-28T10:52:02.568696Z",
     "shell.execute_reply": "2022-12-28T10:52:02.56789Z",
     "shell.execute_reply.started": "2022-12-28T10:52:02.273126Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# --- CONFIGURATION ---\n",
    "image_folder = '/kaggle/input/samples/samples/'\n",
    "TARGET_SIZE = (512, 512)\n",
    "\n",
    "# --- ITERATION LOOP ---\n",
    "\n",
    "for filename in os.listdir(image_folder):\n",
    "    if filename.endswith(\".png\"):\n",
    "        file_path = os.path.join(image_folder, filename)\n",
    "\n",
    "        print(f\"Processing: {filename}\")\n",
    "\n",
    "        try:\n",
    "            # Load, resize, convert to RGB array, and normalize\n",
    "            sample_image = Image.open(file_path).resize(TARGET_SIZE)\n",
    "            np_sample_image = np.array(sample_image.convert(\"RGB\"), dtype=np.float32) / 255.0\n",
    "\n",
    "            # Predict and visualize (calls Cell 2 functions)\n",
    "            pred_mask = show_(np_sample_image) \n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error on {filename}: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 2071681,
     "sourceId": 3438806,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 2735184,
     "sourceId": 4778133,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 8987109,
     "sourceId": 14109222,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 9031040,
     "sourceId": 14168070,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 9035980,
     "sourceId": 14175550,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 9040654,
     "sourceId": 14181318,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30097,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
